{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63cc6e0",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa23838",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c021839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier, XGBRegressor, DMatrix, cv\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'defaultdata.csv'\n",
    "data = pd.read_csv(file_path, header=1)\n",
    "\n",
    "# Rename columns\n",
    "column_mapping = {\n",
    "    'LIMIT_BAL': 'Credit_Limit',\n",
    "    'SEX': 'Gender',\n",
    "    'EDUCATION': 'Education_Level',\n",
    "    'MARRIAGE': 'Marital_Status',\n",
    "    'AGE': 'Age',\n",
    "    'PAY_0': 'Repayment_Status_1',\n",
    "    'PAY_2': 'Repayment_Status_2',\n",
    "    'PAY_3': 'Repayment_Status_3',\n",
    "    'PAY_4': 'Repayment_Status_4',\n",
    "    'PAY_5': 'Repayment_Status_5',\n",
    "    'PAY_6': 'Repayment_Status_6',\n",
    "    'BILL_AMT1': 'Bill_Amount_1',\n",
    "    'BILL_AMT2': 'Bill_Amount_2',\n",
    "    'BILL_AMT3': 'Bill_Amount_3',\n",
    "    'BILL_AMT4': 'Bill_Amount_4',\n",
    "    'BILL_AMT5': 'Bill_Amount_5',\n",
    "    'BILL_AMT6': 'Bill_Amount_6',\n",
    "    'PAY_AMT1': 'Payment_Amount_1',\n",
    "    'PAY_AMT2': 'Payment_Amount_2',\n",
    "    'PAY_AMT3': 'Payment_Amount_3',\n",
    "    'PAY_AMT4': 'Payment_Amount_4',\n",
    "    'PAY_AMT5': 'Payment_Amount_5',\n",
    "    'PAY_AMT6': 'Payment_Amount_6',\n",
    "    'default payment next month': 'Default_Payment'\n",
    "}\n",
    "data.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Clean data\n",
    "data = data[(data['Marital_Status'] != 0) & data['Education_Level'].isin([1, 2, 3])]\n",
    "pay_features = ['Repayment_Status_1', 'Repayment_Status_2', 'Repayment_Status_3', \n",
    "                'Repayment_Status_4', 'Repayment_Status_5', 'Repayment_Status_6']\n",
    "for feature in pay_features:\n",
    "    data.loc[data[feature] < 0, feature] = -1\n",
    "    data.loc[data[feature] >= 0, feature] += 1\n",
    "    data[feature] = data[feature].astype('int64')\n",
    "\n",
    "# Encode features\n",
    "data['Grad_School'] = (data['Education_Level'] == 1).astype('int')\n",
    "data['University'] = (data['Education_Level'] == 2).astype('int')\n",
    "data.drop('Education_Level', axis=1, inplace=True)\n",
    "data['Female'] = (data['Gender'] == 2).astype('int')\n",
    "data['Married'] = (data['Marital_Status'] == 1).astype('int')\n",
    "data.drop(['Gender', 'Marital_Status'], axis=1, inplace=True)\n",
    "data.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb85f57",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61fd67",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93275e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summary statistics for Age\n",
    "age_summary = data['Age'].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "print(\"Summary Statistics for Age:\")\n",
    "print(age_summary)\n",
    "\n",
    "# Histogram and density plot for Age\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Age'], bins=30, kde=True, stat='density', color='gray', edgecolor='black', alpha=0.8)\n",
    "sns.kdeplot(data['Age'], color='black', linewidth=2)\n",
    "plt.title('Age Distribution', fontsize=14, weight='bold')\n",
    "plt.xlabel('Age', fontsize=12, labelpad=10)\n",
    "plt.ylabel('Density', fontsize=12, labelpad=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create Age categories\n",
    "data['Middle_Aged'] = ((data['Age'] > 30) & (data['Age'] <= 50)).astype(int)\n",
    "data['Older'] = (data['Age'] > 50).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60fe87",
   "metadata": {},
   "source": [
    "### Repayment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of Repayment Statuses\n",
    "repayment_status_vars = [\n",
    "    'Repayment_Status_1', 'Repayment_Status_2', 'Repayment_Status_3',\n",
    "    'Repayment_Status_4', 'Repayment_Status_5', 'Repayment_Status_6'\n",
    "]\n",
    "\n",
    "renamed_status_vars = {\n",
    "    'Repayment_Status_1': 'Repayment Status 1',\n",
    "    'Repayment_Status_2': 'Repayment Status 2',\n",
    "    'Repayment_Status_3': 'Repayment Status 3',\n",
    "    'Repayment_Status_4': 'Repayment Status 4',\n",
    "    'Repayment_Status_5': 'Repayment Status 5',\n",
    "    'Repayment_Status_6': 'Repayment Status 6'\n",
    "}\n",
    "\n",
    "repayment_status_counts = {renamed_status_vars[var]: data[var].value_counts(sort=False) for var in repayment_status_vars}\n",
    "repayment_status_df = pd.DataFrame(repayment_status_counts).fillna(0)\n",
    "colors = ['#D3D3D3', '#A9A9A9', '#808080', '#696969', '#505050', '#303030']\n",
    "ax = repayment_status_df.plot(kind='bar', figsize=(12, 8), width=0.8, color=colors, edgecolor='black')\n",
    "plt.title('Distribution of Repayment Status Across All Periods', fontsize=14, weight='bold')\n",
    "plt.xlabel('Repayment Status', fontsize=12, labelpad=10)\n",
    "plt.ylabel('Count', fontsize=12, labelpad=10)\n",
    "plt.legend(title='Period', loc='upper right', fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Repaybar.png', dpi=600) \n",
    "plt.show()\n",
    "\n",
    "# Create Repayment Status categories\n",
    "data['Mild_Delay'] = ((data[repayment_status_vars] == 1).any(axis=1) & \n",
    "                      (data[repayment_status_vars] < 2).all(axis=1)).astype(int)\n",
    "data['Severe_Delay'] = (data[repayment_status_vars] >= 2).any(axis=1).astype(int)\n",
    "data = data[(data['Mild_Delay'] + data['Severe_Delay']) <= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5a955",
   "metadata": {},
   "source": [
    "### Credit Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a154e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summary statistics for Credit Limit\n",
    "credit_limit_summary = data['Credit_Limit'].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "print(\"Summary Statistics for Credit Limit:\")\n",
    "print(credit_limit_summary)\n",
    "\n",
    "# Histogram and density plot for Credit Limit\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Credit_Limit'], bins=30, kde=True, stat='density', color='gray', edgecolor='black', alpha=0.8)\n",
    "sns.kdeplot(data['Credit_Limit'], color='black', linewidth=2)\n",
    "plt.title('Credit Limit Distribution', fontsize=14, weight='bold')\n",
    "plt.xlabel('Credit Limit', fontsize=12, labelpad=10)\n",
    "plt.ylabel('Density', fontsize=12, labelpad=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create Credit Limit categories\n",
    "data['Medium_Credit_Limit'] = ((data['Credit_Limit'] > 50000) & (data['Credit_Limit'] <= 240000)).astype(int)\n",
    "data['High_Credit_Limit'] = (data['Credit_Limit'] > 240000).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4330a",
   "metadata": {},
   "source": [
    "## Key Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6875392",
   "metadata": {},
   "source": [
    "### Create Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f321e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction terms for Repayment Status × Age\n",
    "data['Mild_Delay × Middle_Aged'] = data['Mild_Delay'] * data['Middle_Aged']\n",
    "data['Mild_Delay × Older'] = data['Mild_Delay'] * data['Older']\n",
    "data['Severe_Delay × Middle_Aged'] = data['Severe_Delay'] * data['Middle_Aged']\n",
    "data['Severe_Delay × Older'] = data['Severe_Delay'] * data['Older']\n",
    "\n",
    "# Interaction terms for Repayment Status × Credit Limit \n",
    "data['Medium_Credit_Limit × Mild_Delay'] = data['Medium_Credit_Limit'] * data['Mild_Delay']\n",
    "data['Medium_Credit_Limit × Severe_Delay'] = data['Medium_Credit_Limit'] * data['Severe_Delay']\n",
    "data['High_Credit_Limit × Mild_Delay'] = data['High_Credit_Limit'] * data['Mild_Delay']\n",
    "data['High_Credit_Limit × Severe_Delay'] = data['High_Credit_Limit'] * data['Severe_Delay']\n",
    "\n",
    "# Interaction terms for Education × Marital Status\n",
    "data['Grad_School × Married'] = data['Grad_School'] * data['Married']\n",
    "data['University × Married'] = data['University'] * data['Married']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435cffca",
   "metadata": {},
   "source": [
    "### Interaction Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combinations\n",
    "repayment_age_combinations = {\n",
    "    'Younger & On-Time': (data['Middle_Aged'] == 0) & (data['Older'] == 0) & \n",
    "                         (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 0),\n",
    "    'Middle_Aged & On-Time': (data['Middle_Aged'] == 1) & (data['Older'] == 0) & \n",
    "                              (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 0),\n",
    "    'Older & On-Time': (data['Older'] == 1) & \n",
    "                       (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 0),\n",
    "    'Younger & Mild_Delay': (data['Middle_Aged'] == 0) & (data['Older'] == 0) & \n",
    "                            (data['Mild_Delay'] == 1) & (data['Severe_Delay'] == 0),\n",
    "    'Middle_Aged & Mild_Delay': (data['Middle_Aged'] == 1) & (data['Older'] == 0) & \n",
    "                                 (data['Mild_Delay'] == 1) & (data['Severe_Delay'] == 0),\n",
    "    'Older & Mild_Delay': (data['Older'] == 1) & \n",
    "                          (data['Mild_Delay'] == 1) & (data['Severe_Delay'] == 0),\n",
    "    'Younger & Severe_Delay': (data['Middle_Aged'] == 0) & (data['Older'] == 0) & \n",
    "                              (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 1),\n",
    "    'Middle_Aged & Severe_Delay': (data['Middle_Aged'] == 1) & (data['Older'] == 0) & \n",
    "                                   (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 1),\n",
    "    'Older & Severe_Delay': (data['Older'] == 1) & \n",
    "                            (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 1)\n",
    "}\n",
    "\n",
    "credit_limit_repayment_combinations = {\n",
    "    'Low Credit & On-Time': (data['Medium_Credit_Limit'] == 0) & (data['High_Credit_Limit'] == 0) & \n",
    "                            (data['Mild_Delay'] == 0) & (data['Severe_Delay'] == 0),\n",
    "    'Medium Credit & On-Time': (data['Medium_Credit_Limit'] == 1) & (data['Mild_Delay'] == 0) & \n",
    "                               (data['Severe_Delay'] == 0),\n",
    "    'High Credit & On-Time': (data['High_Credit_Limit'] == 1) & (data['Mild_Delay'] == 0) & \n",
    "                             (data['Severe_Delay'] == 0),\n",
    "    'Low Credit & Mild_Delay': (data['Medium_Credit_Limit'] == 0) & (data['High_Credit_Limit'] == 0) & \n",
    "                               (data['Mild_Delay'] == 1),\n",
    "    'Medium Credit & Mild_Delay': (data['Medium_Credit_Limit'] == 1) & (data['Mild_Delay'] == 1),\n",
    "    'High Credit & Mild_Delay': (data['High_Credit_Limit'] == 1) & (data['Mild_Delay'] == 1),\n",
    "    'Low Credit & Severe_Delay': (data['Medium_Credit_Limit'] == 0) & (data['High_Credit_Limit'] == 0) & \n",
    "                                 (data['Severe_Delay'] == 1),\n",
    "    'Medium Credit & Severe_Delay': (data['Medium_Credit_Limit'] == 1) & (data['Severe_Delay'] == 1),\n",
    "    'High Credit & Severe_Delay': (data['High_Credit_Limit'] == 1) & (data['Severe_Delay'] == 1)\n",
    "}\n",
    "\n",
    "education_marital_combinations = {\n",
    "    'High School & Single': (data['Grad_School'] == 0) & (data['University'] == 0) & (data['Married'] == 0),\n",
    "    'Grad School & Single': (data['Grad_School'] == 1) & (data['Married'] == 0),\n",
    "    'University & Single': (data['University'] == 1) & (data['Married'] == 0),\n",
    "    'High School & Married': (data['Grad_School'] == 0) & (data['University'] == 0) & (data['Married'] == 1),\n",
    "    'Grad School & Married': (data['Grad_School'] == 1) & (data['Married'] == 1),\n",
    "    'University & Married': (data['University'] == 1) & (data['Married'] == 1)\n",
    "}\n",
    "\n",
    "# Summary table generation\n",
    "def calculate_combinations(combinations, total_count):\n",
    "    stats = {k: v.sum() for k, v in combinations.items()}\n",
    "    percentages = {k: (v / total_count) * 100 for k, v in stats.items()}\n",
    "    return pd.DataFrame({'Count': stats, 'Percentage (%)': percentages})\n",
    "\n",
    "total_count = len(data)\n",
    "repayment_age_table = calculate_combinations(repayment_age_combinations, total_count)\n",
    "credit_limit_repayment_table = calculate_combinations(credit_limit_repayment_combinations, total_count)\n",
    "education_marital_table = calculate_combinations(education_marital_combinations, total_count)\n",
    "\n",
    "print(\"Repayment Status × Age Combinations:\")\n",
    "print(repayment_age_table)\n",
    "print(\"\\nCredit Limit × Repayment Status Combinations:\")\n",
    "print(credit_limit_repayment_table)\n",
    "print(\"\\nEducation × Marital Status Combinations:\")\n",
    "print(education_marital_table)\n",
    "\n",
    "# Default vs. Non-Default proportions\n",
    "def calculate_default_proportions(combinations):\n",
    "    proportions = {}\n",
    "    for label, condition in combinations.items():\n",
    "        subset = data[condition]\n",
    "        default_counts = subset['Default_Payment'].value_counts(normalize=True) * 100\n",
    "        proportions[label] = default_counts.reindex([0, 1], fill_value=0)\n",
    "    return pd.DataFrame(proportions).T.rename(columns={0: 'Non-Default (%)', 1: 'Default (%)'})\n",
    "\n",
    "repayment_age_default_proportions = calculate_default_proportions(repayment_age_combinations)\n",
    "credit_limit_repayment_default_proportions = calculate_default_proportions(credit_limit_repayment_combinations)\n",
    "education_marital_default_proportions = calculate_default_proportions(education_marital_combinations)\n",
    "\n",
    "print(\"\\nProportion of Default vs Non-Default for Repayment Status × Age Combinations:\")\n",
    "print(repayment_age_default_proportions)\n",
    "print(\"\\nProportion of Default vs Non-Default for Credit Limit × Repayment Status Combinations:\")\n",
    "print(credit_limit_repayment_default_proportions)\n",
    "print(\"\\nProportion of Default vs Non-Default for Education × Marital Status Combinations:\")\n",
    "print(education_marital_default_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc83e67",
   "metadata": {},
   "source": [
    "### General Summary Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484642ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate base cases\n",
    "base_cases = {\n",
    "    \"Young (<30)\": len(data.query(\"Middle_Aged == 0 & Older == 0\")),\n",
    "    \"On Time Payment\": len(data.query(\"Mild_Delay == 0 & Severe_Delay == 0\")),\n",
    "    \"Low Credit Limit\": len(data.query(\"Medium_Credit_Limit == 0 & High_Credit_Limit == 0\")),\n",
    "    \"High School\": len(data[(data[\"Grad_School\"] == 0) & (data[\"University\"] == 0)]),\n",
    "    \"Not Married\": data[\"Married\"].value_counts().get(0, 0),\n",
    "}\n",
    "\n",
    "# Variables of interest\n",
    "categorical_vars = [\n",
    "    \"Default_Payment\", \"Grad_School\", \"University\", \"Female\", \"Married\", \n",
    "    \"Middle_Aged\", \"Older\", \"Mild_Delay\", \"Severe_Delay\", \n",
    "    \"Medium_Credit_Limit\", \"High_Credit_Limit\"\n",
    "]\n",
    "\n",
    "# Initialize summary dictionary\n",
    "summary = {\"Variable\": [], \"Category\": [], \"Count\": [], \"% of Sample\": []}\n",
    "\n",
    "# Summarize categorical variables\n",
    "for var in categorical_vars:\n",
    "    for category in data[var].unique():\n",
    "        count = len(data[data[var] == category])\n",
    "        pct = (count / len(data)) * 100\n",
    "        summary[\"Variable\"].append(var)\n",
    "        summary[\"Category\"].append(f\"{var} = {category}\")\n",
    "        summary[\"Count\"].append(count)\n",
    "        summary[\"% of Sample\"].append(round(pct, 2))\n",
    "\n",
    "# Add base cases\n",
    "for base_case, count in base_cases.items():\n",
    "    summary[\"Variable\"].append(base_case)\n",
    "    summary[\"Category\"].append(\"Base Case\")\n",
    "    summary[\"Count\"].append(count)\n",
    "    summary[\"% of Sample\"].append(round((count / len(data)) * 100, 2))\n",
    "\n",
    "# Add stats for Default_Payment\n",
    "default_1_count = len(data[data[\"Default_Payment\"] == 1])\n",
    "default_0_count = len(data[data[\"Default_Payment\"] == 0])\n",
    "summary[\"Variable\"].extend([\"Default_Payment\", \"Default_Payment\"])\n",
    "summary[\"Category\"].extend([\"Default = 1\", \"Not Default = 0\"])\n",
    "summary[\"Count\"].extend([default_1_count, default_0_count])\n",
    "summary[\"% of Sample\"].extend([\n",
    "    round((default_1_count / len(data)) * 100, 2), \n",
    "    round((default_0_count / len(data)) * 100, 2)\n",
    "])\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6b8f5",
   "metadata": {},
   "source": [
    "## X-Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f5545",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified interaction terms\n",
    "interaction_terms_to_remove = [\n",
    "    'Mild_Delay × Middle_Aged', 'Mild_Delay × Older', 'Severe_Delay × Middle_Aged', \n",
    "    'Severe_Delay × Older', 'Medium_Credit_Limit × Mild_Delay', \n",
    "    'Medium_Credit_Limit × Severe_Delay', 'High_Credit_Limit × Mild_Delay', \n",
    "    'High_Credit_Limit × Severe_Delay', 'Grad_School × Married', \n",
    "    'University × Married'\n",
    "]\n",
    "data = data.drop(columns=interaction_terms_to_remove, errors='ignore')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(columns=['Default_Payment'])\n",
    "y = data['Default_Payment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b536b",
   "metadata": {},
   "source": [
    "### Repayment Status × Age Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56708b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define subgroups for Repayment Status × Age\n",
    "interaction_groups = {\n",
    "    'Younger & On-Time': (X['Middle_Aged'] == 0) & (X['Older'] == 0) & \n",
    "                         (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 0),\n",
    "    'Middle_Aged & On-Time': (X['Middle_Aged'] == 1) & (X['Older'] == 0) & \n",
    "                              (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 0),\n",
    "    'Older & On-Time': (X['Older'] == 1) & \n",
    "                       (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 0),\n",
    "    'Younger & Mild_Delay': (X['Middle_Aged'] == 0) & (X['Older'] == 0) & \n",
    "                            (X['Mild_Delay'] == 1) & (X['Severe_Delay'] == 0),\n",
    "    'Middle_Aged & Mild_Delay': (X['Middle_Aged'] == 1) & (X['Older'] == 0) & \n",
    "                                 (X['Mild_Delay'] == 1) & (X['Severe_Delay'] == 0),\n",
    "    'Older & Mild_Delay': (X['Older'] == 1) & \n",
    "                          (X['Mild_Delay'] == 1) & (X['Severe_Delay'] == 0),\n",
    "    'Younger & Severe_Delay': (X['Middle_Aged'] == 0) & (X['Older'] == 0) & \n",
    "                              (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 1),\n",
    "    'Middle_Aged & Severe_Delay': (X['Middle_Aged'] == 1) & (X['Older'] == 0) & \n",
    "                                   (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 1),\n",
    "    'Older & Severe_Delay': (X['Older'] == 1) & \n",
    "                            (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 1)\n",
    "}\n",
    "\n",
    "# Dictionary to store final CATE results and confidence intervals\n",
    "cate_results = {}\n",
    "\n",
    "# CV function\n",
    "def xgb_cv_optimization(X, y, params, model_type, nfold=5, verbose_eval=False):\n",
    "    dmatrix = DMatrix(data=X, label=y)\n",
    "    \n",
    "    # Determine metrics and stratification\n",
    "    if model_type == 'classifier':\n",
    "        metrics = 'auc'\n",
    "        stratified = True\n",
    "    else:\n",
    "        metrics = 'rmse'\n",
    "        stratified = False\n",
    "    \n",
    "    # Perform CV\n",
    "    cv_results = cv(\n",
    "        params=params,\n",
    "        dtrain=dmatrix,\n",
    "        num_boost_round=200,\n",
    "        nfold=nfold,\n",
    "        metrics=metrics,\n",
    "        stratified=stratified,\n",
    "        early_stopping_rounds=10,\n",
    "        seed=42,\n",
    "        verbose_eval=verbose_eval\n",
    "    )\n",
    "    return len(cv_results)\n",
    "\n",
    "# Bootstrapping function\n",
    "def bootstrap_cate(X, y, treat, num_bootstrap):\n",
    "    bootstrap_cates = []\n",
    "    for i in range(num_bootstrap):\n",
    "        X_resampled, y_resampled, treat_resampled = resample(X, y, treat, random_state=i)\n",
    "        \n",
    "        # Fit models for bootstrap sample\n",
    "        propensity_model.fit(X_resampled, treat_resampled)\n",
    "        propensity_scores = propensity_model.predict_proba(X_resampled)[:, 1]\n",
    "        \n",
    "        treated_indices = treat_resampled == 1\n",
    "        control_indices = treat_resampled == 0\n",
    "        \n",
    "        treated_model.fit(X_resampled[treated_indices], y_resampled[treated_indices])\n",
    "        control_model.fit(X_resampled[control_indices], y_resampled[control_indices])\n",
    "        \n",
    "        treated_preds = treated_model.predict(X)\n",
    "        control_preds = control_model.predict(X)\n",
    "        treatment_effects = treated_preds - control_preds\n",
    "        \n",
    "        # Combine effects\n",
    "        refined_treated_model.fit(X_resampled[treated_indices], treatment_effects[treated_indices])\n",
    "        refined_control_model.fit(X_resampled[control_indices], treatment_effects[control_indices])\n",
    "        \n",
    "        refined_treated_preds = refined_treated_model.predict(X)\n",
    "        refined_control_preds = refined_control_model.predict(X)\n",
    "        \n",
    "        cate_combined = (propensity_scores * refined_treated_preds +\n",
    "                         (1 - propensity_scores) * refined_control_preds)\n",
    "        bootstrap_cates.append(cate_combined.mean())\n",
    "    return np.array(bootstrap_cates)\n",
    "\n",
    "# Loop through each group\n",
    "for group_name, condition in interaction_groups.items():\n",
    "    print(f\"Processing group: {group_name}\")\n",
    "    \n",
    "    # Define treatment variable\n",
    "    treat = condition.astype(int)\n",
    "    \n",
    "    # Step 1: Propensity Score Estimation with XGBClassifier\n",
    "    propensity_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'auc',\n",
    "        'seed': 42\n",
    "    }\n",
    "    best_num_boost_rounds = xgb_cv_optimization(X, treat, propensity_params, model_type='classifier', verbose_eval=False)\n",
    "    propensity_model = XGBClassifier(\n",
    "        n_estimators=best_num_boost_rounds,\n",
    "        random_state=42,\n",
    "        **propensity_params\n",
    "    )\n",
    "    propensity_model.fit(X, treat)\n",
    "    propensity_scores = propensity_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Step 2: Fit Conditional Outcome Models\n",
    "    treated_indices = X[treat == 1].index\n",
    "    control_indices = X[treat == 0].index\n",
    "    \n",
    "    treated_outcome = y.loc[treated_indices]\n",
    "    control_outcome = y.loc[control_indices]\n",
    "    \n",
    "    treated_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 42\n",
    "    }\n",
    "    best_num_boost_rounds_treated = xgb_cv_optimization(\n",
    "        X.loc[treated_indices], treated_outcome, treated_params, model_type='regressor', verbose_eval=False\n",
    "    )\n",
    "    treated_model = XGBRegressor(\n",
    "        n_estimators=best_num_boost_rounds_treated,\n",
    "        random_state=42,\n",
    "        **treated_params\n",
    "    )\n",
    "    treated_model.fit(X.loc[treated_indices], treated_outcome)\n",
    "    \n",
    "    best_num_boost_rounds_control = xgb_cv_optimization(\n",
    "        X.loc[control_indices], control_outcome, treated_params, model_type='regressor', verbose_eval=False\n",
    "    )\n",
    "    control_model = XGBRegressor(\n",
    "        n_estimators=best_num_boost_rounds_control,\n",
    "        random_state=42,\n",
    "        **treated_params\n",
    "    )\n",
    "    control_model.fit(X.loc[control_indices], control_outcome)\n",
    "    \n",
    "    treated_preds = treated_model.predict(X)\n",
    "    control_preds = control_model.predict(X)\n",
    "    treatment_effects = treated_preds - control_preds\n",
    "    \n",
    "    refined_treated_model = XGBRegressor(**treated_params)\n",
    "    refined_control_model = XGBRegressor(**treated_params)\n",
    "    \n",
    "    refined_treated_model.fit(X[treat == 1], treatment_effects[treat == 1])\n",
    "    refined_control_model.fit(X[treat == 0], treatment_effects[treat == 0])\n",
    "    \n",
    "    refined_treated_preds = refined_treated_model.predict(X)\n",
    "    refined_control_preds = refined_control_model.predict(X)\n",
    "    \n",
    "    cate_combined = (propensity_scores * refined_treated_preds +\n",
    "                     (1 - propensity_scores) * refined_control_preds)\n",
    "    \n",
    "    # Bootstrap CATE\n",
    "    bootstrap_cates = bootstrap_cate(X, y, treat, num_bootstrap=1000)\n",
    "    cate_mean = cate_combined.mean()\n",
    "    cate_ci_lower = np.percentile(bootstrap_cates, 2.5)\n",
    "    cate_ci_upper = np.percentile(bootstrap_cates, 97.5)\n",
    "    \n",
    "    # Store results\n",
    "    cate_results[group_name] = {\n",
    "        'CATE Mean': cate_mean,\n",
    "        'CI Lower': cate_ci_lower,\n",
    "        'CI Upper': cate_ci_upper\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "cate_df = pd.DataFrame.from_dict(cate_results, orient='index')\n",
    "print(cate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dd811f",
   "metadata": {},
   "source": [
    "### Repayment Status × Credit Limit Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830508cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subgroups for Credit Limit × Repayment Status\n",
    "interaction_groups = {\n",
    "    'Low Credit & On-Time': (X['Medium_Credit_Limit'] == 0) & (X['High_Credit_Limit'] == 0) & \n",
    "                            (X['Mild_Delay'] == 0) & (X['Severe_Delay'] == 0),\n",
    "    'Medium Credit & On-Time': (X['Medium_Credit_Limit'] == 1) & (X['Mild_Delay'] == 0) & \n",
    "                               (X['Severe_Delay'] == 0),\n",
    "    'High Credit & On-Time': (X['High_Credit_Limit'] == 1) & (X['Mild_Delay'] == 0) & \n",
    "                             (X['Severe_Delay'] == 0),\n",
    "    'Low Credit & Mild_Delay': (X['Medium_Credit_Limit'] == 0) & (X['High_Credit_Limit'] == 0) & \n",
    "                               (X['Mild_Delay'] == 1),\n",
    "    'Medium Credit & Mild_Delay': (X['Medium_Credit_Limit'] == 1) & (X['Mild_Delay'] == 1),\n",
    "    'High Credit & Mild_Delay': (X['High_Credit_Limit'] == 1) & (X['Mild_Delay'] == 1),\n",
    "    'Low Credit & Severe_Delay': (X['Medium_Credit_Limit'] == 0) & (X['High_Credit_Limit'] == 0) & \n",
    "                                 (X['Severe_Delay'] == 1),\n",
    "    'Medium Credit & Severe_Delay': (X['Medium_Credit_Limit'] == 1) & (X['Severe_Delay'] == 1),\n",
    "    'High Credit & Severe_Delay': (X['High_Credit_Limit'] == 1) & (X['Severe_Delay'] == 1)\n",
    "}\n",
    "\n",
    "# Dictionary to store final CATE results and confidence intervals\n",
    "cate_results = {}\n",
    "\n",
    "# CV function\n",
    "def xgb_cv_optimization(X, y, params, model_type, nfold=5, verbose_eval=False):\n",
    "    dmatrix = DMatrix(data=X, label=y)\n",
    "    \n",
    "    # Determine metrics and stratification\n",
    "    if model_type == 'classifier':\n",
    "        metrics = 'auc'\n",
    "        stratified = True\n",
    "    else:\n",
    "        metrics = 'rmse'\n",
    "        stratified = False\n",
    "    \n",
    "    # Perform CV\n",
    "    cv_results = cv(\n",
    "        params=params,\n",
    "        dtrain=dmatrix,\n",
    "        num_boost_round=200,\n",
    "        nfold=nfold,\n",
    "        metrics=metrics,\n",
    "        stratified=stratified,\n",
    "        early_stopping_rounds=10,\n",
    "        seed=42,\n",
    "        verbose_eval=verbose_eval\n",
    "    )\n",
    "    return len(cv_results)\n",
    "\n",
    "# Bootstrapping function\n",
    "def bootstrap_cate(X, y, treat, num_bootstrap):\n",
    "    bootstrap_cates = []\n",
    "    for i in range(num_bootstrap):\n",
    "        X_resampled, y_resampled, treat_resampled = resample(X, y, treat, random_state=i)\n",
    "        \n",
    "        # Fit models for bootstrap sample\n",
    "        propensity_model.fit(X_resampled, treat_resampled)\n",
    "        propensity_scores = propensity_model.predict_proba(X_resampled)[:, 1]\n",
    "        \n",
    "        treated_indices = treat_resampled == 1\n",
    "        control_indices = treat_resampled == 0\n",
    "        \n",
    "        treated_model.fit(X_resampled[treated_indices], y_resampled[treated_indices])\n",
    "        control_model.fit(X_resampled[control_indices], y_resampled[control_indices])\n",
    "        \n",
    "        treated_preds = treated_model.predict(X)\n",
    "        control_preds = control_model.predict(X)\n",
    "        treatment_effects = treated_preds - control_preds\n",
    "        \n",
    "        # Combine effects\n",
    "        refined_treated_model.fit(X_resampled[treated_indices], treatment_effects[treated_indices])\n",
    "        refined_control_model.fit(X_resampled[control_indices], treatment_effects[control_indices])\n",
    "        \n",
    "        refined_treated_preds = refined_treated_model.predict(X)\n",
    "        refined_control_preds = refined_control_model.predict(X)\n",
    "        \n",
    "        cate_combined = (propensity_scores * refined_treated_preds +\n",
    "                         (1 - propensity_scores) * refined_control_preds)\n",
    "        bootstrap_cates.append(cate_combined.mean())\n",
    "    return np.array(bootstrap_cates)\n",
    "\n",
    "# Loop through each group\n",
    "for group_name, condition in interaction_groups.items():\n",
    "    print(f\"Processing group: {group_name}\")\n",
    "    \n",
    "    # Define treatment variable\n",
    "    treat = condition.astype(int)\n",
    "    \n",
    "    # Step 1: Propensity Score Estimation with XGBClassifier\n",
    "    propensity_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'auc',\n",
    "        'seed': 42\n",
    "    }\n",
    "    best_num_boost_rounds = xgb_cv_optimization(X, treat, propensity_params, model_type='classifier', verbose_eval=False)\n",
    "    propensity_model = XGBClassifier(\n",
    "        n_estimators=best_num_boost_rounds,\n",
    "        random_state=42,\n",
    "        **propensity_params\n",
    "    )\n",
    "    propensity_model.fit(X, treat)\n",
    "    propensity_scores = propensity_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Step 2: Fit Conditional Outcome Models\n",
    "    treated_indices = X[treat == 1].index\n",
    "    control_indices = X[treat == 0].index\n",
    "    \n",
    "    treated_outcome = y.loc[treated_indices]\n",
    "    control_outcome = y.loc[control_indices]\n",
    "    \n",
    "    treated_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 42\n",
    "    }\n",
    "    best_num_boost_rounds_treated = xgb_cv_optimization(\n",
    "        X.loc[treated_indices], treated_outcome, treated_params, model_type='regressor', verbose_eval=False\n",
    "    )\n",
    "    treated_model = XGBRegressor(\n",
    "        n_estimators=best_num_boost_rounds_treated,\n",
    "        random_state=42,\n",
    "        **treated_params\n",
    "    )\n",
    "    treated_model.fit(X.loc[treated_indices], treated_outcome)\n",
    "    \n",
    "    best_num_boost_rounds_control = xgb_cv_optimization(\n",
    "        X.loc[control_indices], control_outcome, treated_params, model_type='regressor', verbose_eval=False\n",
    "    )\n",
    "    control_model = XGBRegressor(\n",
    "        n_estimators=best_num_boost_rounds_control,\n",
    "        random_state=42,\n",
    "        **treated_params\n",
    "    )\n",
    "    control_model.fit(X.loc[control_indices], control_outcome)\n",
    "    \n",
    "    treated_preds = treated_model.predict(X)\n",
    "    control_preds = control_model.predict(X)\n",
    "    treatment_effects = treated_preds - control_preds\n",
    "    \n",
    "    refined_treated_model = XGBRegressor(**treated_params)\n",
    "    refined_control_model = XGBRegressor(**treated_params)\n",
    "    \n",
    "    refined_treated_model.fit(X[treat == 1], treatment_effects[treat == 1])\n",
    "    refined_control_model.fit(X[treat == 0], treatment_effects[treat == 0])\n",
    "    \n",
    "    refined_treated_preds = refined_treated_model.predict(X)\n",
    "    refined_control_preds = refined_control_model.predict(X)\n",
    "    \n",
    "    cate_combined = (propensity_scores * refined_treated_preds +\n",
    "                     (1 - propensity_scores) * refined_control_preds)\n",
    "    \n",
    "    # Bootstrap CATE\n",
    "    bootstrap_cates = bootstrap_cate(X, y, treat, num_bootstrap=1000)\n",
    "    cate_mean = cate_combined.mean()\n",
    "    cate_ci_lower = np.percentile(bootstrap_cates, 2.5)\n",
    "    cate_ci_upper = np.percentile(bootstrap_cates, 97.5)\n",
    "    \n",
    "    # Store results\n",
    "    cate_results[group_name] = {\n",
    "        'CATE Mean': cate_mean,\n",
    "        'CI Lower': cate_ci_lower,\n",
    "        'CI Upper': cate_ci_upper\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "cate_df = pd.DataFrame.from_dict(cate_results, orient='index')\n",
    "print(cate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f03e6",
   "metadata": {},
   "source": [
    "### Education × Martial Status Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subgroups for Education × Marital Status\n",
    "interaction_groups = {\n",
    "    'High School & Single': (X['Grad_School'] == 0) & (X['University'] == 0) & (X['Married'] == 0),\n",
    "    'Grad School & Single': (X['Grad_School'] == 1) & (X['Married'] == 0),\n",
    "    'University & Single': (X['University'] == 1) & (X['Married'] == 0),\n",
    "    'High School & Married': (X['Grad_School'] == 0) & (X['University'] == 0) & (X['Married'] == 1),\n",
    "    'Grad School & Married': (X['Grad_School'] == 1) & (X['Married'] == 1),\n",
    "    'University & Married': (X['University'] == 1) & (X['Married'] == 1)\n",
    "}\n",
    "\n",
    "# Dictionary to store final CATE results and confidence intervals\n",
    "cate_results = {}\n",
    "\n",
    "# CV function\n",
    "def xgb_cv_optimization(X, y, params, model_type, nfold=5, verbose_eval=False):\n",
    "    dmatrix = DMatrix(data=X, label=y)\n",
    "    \n",
    "    # Determine metrics and stratification\n",
    "    if model_type == 'classifier':\n",
    "        metrics = 'auc'\n",
    "        stratified = True\n",
    "    else:\n",
    "        metrics = 'rmse'\n",
    "        stratified = False\n",
    "    \n",
    "    # Perform CV\n",
    "    cv_results = cv(\n",
    "        params=params,\n",
    "        dtrain=dmatrix,\n",
    "        num_boost_round=200,\n",
    "        nfold=nfold,\n",
    "        metrics=metrics,\n",
    "        stratified=stratified,\n",
    "        early_stopping_rounds=10,\n",
    "        seed=42,\n",
    "        verbose_eval=verbose_eval\n",
    "    )\n",
    "    return len(cv_results)\n",
    "\n",
    "# Bootstrapping function\n",
    "def bootstrap_cate(X, y, treat, num_bootstrap):\n",
    "    bootstrap_cates = []\n",
    "    for i in range(num_bootstrap):\n",
    "        X_resampled, y_resampled, treat_resampled = resample(X, y, treat, random_state=i)\n",
    "        \n",
    "        # Fit models for bootstrap sample\n",
    "        propensity_model.fit(X_resampled, treat_resampled)\n",
    "        propensity_scores = propensity_model.predict_proba(X_resampled)[:, 1]\n",
    "        \n",
    "        treated_indices = treat_resampled == 1\n",
    "        control_indices = treat_resampled == 0\n",
    "        \n",
    "        treated_model.fit(X_resampled[treated_indices], y_resampled[treated_indices])\n",
    "        control_model.fit(X_resampled[control_indices], y_resampled[control_indices])\n",
    "        \n",
    "        treated_preds = treated_model.predict(X)\n",
    "        control_preds = control_model.predict(X)\n",
    "        treatment_effects = treated_preds - control_preds\n",
    "        \n",
    "        # Combine effects\n",
    "        refined_treated_model.fit(X_resampled[treated_indices], treatment_effects[treated_indices])\n",
    "        refined_control_model.fit(X_resampled[control_indices], treatment_effects[control_indices])\n",
    "        \n",
    "        refined_treated_preds = refined_treated_model.predict(X)\n",
    "        refined_control_preds = refined_control_model.predict(X)\n",
    "        \n",
    "        cate_combined = (propensity_scores * refined_treated_preds +\n",
    "                         (1 - propensity_scores) * refined_control_preds)\n",
    "        bootstrap_cates.append(cate_combined.mean())\n",
    "    return np.array(bootstrap_cates)\n",
    "\n",
    "# Loop through each group\n",
    "for group_name, condition in interaction_groups.items():\n",
    "    print(f\"Processing group: {group_name}\")\n",
    "    \n",
    "    # Define treatment variable\n",
    "    treat = condition.astype(int)\n",
    "    \n",
    "    # Step 1: Propensity Score Estimation with XGBClassifier\n",
    "    propensity_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'auc',\n",
    "        'seed': 42\n",
    "    }\n",
    "    best_num_boost_rounds = xgb_cv_optimization(X, treat, propensity_params, model_type='classifier', verbose_eval=False)\n",
    "    propensity_model = XGBClassifier(\n",
    "        n_estimators=best_num_boost_rounds,\n",
    "        random_state=42,\n",
    "        **propensity_params\n",
    "    )\n",
    "    propensity_model.fit(X, treat)\n",
    "    propensity_scores = propensity_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Step 2: Fit Conditional Outcome Models\n",
    "    treated_indices = X[treat == 1].index\n",
    "    control_indices = X[treat == 0].index\n",
    "    \n",
    "    treated_outcome = y.loc[treated_indices]\n",
    "    control_outcome = y.loc[control_indices]\n",
    "    \n",
    "    treated_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': 42\n",
    "    }\n",
    "    best_num_boost_rounds_treated = xgb_cv_optimization(\n",
    "        X.loc[treated_indices], treated_outcome, treated_params, model_type='regressor', verbose_eval=False\n",
    "    )\n",
    "    treated_model = XGBRegressor(\n",
    "        n_estimators=best_num_boost_rounds_treated,\n",
    "        random_state=42,\n",
    "        **treated_params\n",
    "    )\n",
    "    treated_model.fit(X.loc[treated_indices], treated_outcome)\n",
    "    \n",
    "    best_num_boost_rounds_control = xgb_cv_optimization(\n",
    "        X.loc[control_indices], control_outcome, treated_params, model_type='regressor', verbose_eval=False\n",
    "    )\n",
    "    control_model = XGBRegressor(\n",
    "        n_estimators=best_num_boost_rounds_control,\n",
    "        random_state=42,\n",
    "        **treated_params\n",
    "    )\n",
    "    control_model.fit(X.loc[control_indices], control_outcome)\n",
    "    \n",
    "    treated_preds = treated_model.predict(X)\n",
    "    control_preds = control_model.predict(X)\n",
    "    treatment_effects = treated_preds - control_preds\n",
    "    \n",
    "    refined_treated_model = XGBRegressor(**treated_params)\n",
    "    refined_control_model = XGBRegressor(**treated_params)\n",
    "    \n",
    "    refined_treated_model.fit(X[treat == 1], treatment_effects[treat == 1])\n",
    "    refined_control_model.fit(X[treat == 0], treatment_effects[treat == 0])\n",
    "    \n",
    "    refined_treated_preds = refined_treated_model.predict(X)\n",
    "    refined_control_preds = refined_control_model.predict(X)\n",
    "    \n",
    "    cate_combined = (propensity_scores * refined_treated_preds +\n",
    "                     (1 - propensity_scores) * refined_control_preds)\n",
    "    \n",
    "    # Bootstrap CATE\n",
    "    bootstrap_cates = bootstrap_cate(X, y, treat, num_bootstrap=1000)\n",
    "    cate_mean = cate_combined.mean()\n",
    "    cate_ci_lower = np.percentile(bootstrap_cates, 2.5)\n",
    "    cate_ci_upper = np.percentile(bootstrap_cates, 97.5)\n",
    "    \n",
    "    # Store results\n",
    "    cate_results[group_name] = {\n",
    "        'CATE Mean': cate_mean,\n",
    "        'CI Lower': cate_ci_lower,\n",
    "        'CI Upper': cate_ci_upper\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "cate_df = pd.DataFrame.from_dict(cate_results, orient='index')\n",
    "print(cate_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
